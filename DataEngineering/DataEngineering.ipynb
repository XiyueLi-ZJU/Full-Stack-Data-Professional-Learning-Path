{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main responsibility of a data engineer is to build and maintain data pipelines to ensure timely data delivery and proper data storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **key responsibilities** of a data engineer typically include:\n",
    "\n",
    "1. **Developing and maintaining Data pipeline** to \n",
    "    - Ingest data from various data sources such as APIs, IOT devices, streaming platforms, and databases,\n",
    "    - **Extract** required data and **Transform** data to enable efficient data query and analysis, \n",
    "    - **Load** data in storage systems and store data in a secure and cost-efficient way. \n",
    "\n",
    "    Question: ETL VS ELT? [AWS - What’s the Difference Between ETL and ELT?](https://aws.amazon.com/compare/the-difference-between-etl-and-elt/#:~:text=ELT%20is%20faster%20than%20ETL,and%20transforms%20it%20in%20parallel.)\n",
    "\n",
    "2. **Implmenting data quality checks** to monitor and control the quality of data throughout the pipeline and make sure data is appropriate for its intended use. \n",
    "\n",
    "    Question: How to evaluate data quality?\n",
    "    - Completeness (Is all the required data present?)\n",
    "    - Uniqueness (Are all features unique?)\n",
    "    - Validity (Is the data valid?)\n",
    "    - Timeliness (Is the data up to date?)\n",
    "    - Accuracy (How well does the data reflect reality?)\n",
    "    - Consistency (Is the data consistent?) \n",
    "\n",
    "3. **Monitoring and continuously improving** existing data pipelines and solutions to achieve better performance and proactively identify and address issues that may impact the business. \n",
    "\n",
    "4. **Documenting solutions** to let all team members understand or at least be aware of the solutions you provide. This is critical for process improvement and business continuity, but is often overlooked.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fulfill these responsibilities, **collaboration** is an important part of a data engineer's daily activities. \n",
    "- Data Engineers collaborate with the Solutions Architect team to implement data architecture/infrastructure solutions that align with the overall architecting strategy and meet business requirements. \n",
    "- Data Engineers collaborate with the Data Science team to understand data requirements and deliver data on time. \n",
    "- Data Engineers work with the Data Governance team to ensure data security and regulatory compliance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Engineering **tech stack**:\n",
    "\n",
    "1. Programming Languages: Python, SQL, Java, Scala\n",
    "2. ETL (Extract, Transform, Load) Tools, Data Pipeline Orchestration: Apache Airflow, Apache NiFi, Azure Data Factory, AWS Glue\n",
    "    - [Medium - Apache Airflow vs Apache NiFi: A Comprehensive Comparison](https://medium.com/illumination/apache-airflow-vs-apache-nifi-a-comprehensive-comparison-b7f55d5998f4)\n",
    "\n",
    "3. Data Processing Frameworks: Apache Spark (batch processing), Apache Flink (streaming data), Apache Beam (batch & streaming)\n",
    "    - [Medium - Apache Spark vs. Apache Flink: A Comprehensive Comparison](https://medium.com/@ansam.yousry/apache-spark-vs-apache-flink-a-comprehensive-comparison-104bf543869a#:~:text=Spark%20uses%20a%20batch%20processing,support%20for%20in%2Dmemory%20processing.)\n",
    "    - [Medium - Apache spark vs Apache Beam — What to choose & when?](https://shashwat-pandey.medium.com/apache-spark-vs-apache-beam-what-to-choose-when-94f938d0317f)\n",
    "4. Data Warehousing: Amazon Redshift, Azure Synapse Analytics, Google BigQuery, Snowflake\n",
    "5. Version Control, CI/CD: Git, GitHub, GitLab, Bitbucket\n",
    "6. Cloud Platforms: Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
