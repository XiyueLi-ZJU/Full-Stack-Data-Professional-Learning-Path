{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Data Engineer of the ðŸŒ±Sqaure Meter GardeningðŸŒ± project, you are responsible for providing the marketing team a **weekly KPI report**. The datapipeline includes (1) extracting data from database and (2) processing data to get required KPIs. To improve work efficiency, reduce errors that may occur in manual work, and ensure the consistency and reliability of the reporting work, you decide to automate this repetitive task using [Apache Airflow](https://airflow.apache.org/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KPI_Reporting_DAG](./KPI_Reporting_DAG.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.postgres_operator import PostgresOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'DataEngineeringTeam',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime.now(),\n",
    "    'email': ['data_engineer@YourSquaremetergardening.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': True,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'weekly_kpi_report',\n",
    "    default_args=default_args,\n",
    "    description='Data Pipeline for Sqaure Meter Gardening project weekly KPI report',\n",
    "    schedule_interval='59 23 * * 0',  # Run at 23:59PM every Sunday\n",
    "    catchup=False,\n",
    ")\n",
    "\n",
    "def fetch_data():\n",
    "    # Connect to PostgreSQL database and fetch data\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"gardening_commerce_db\",\n",
    "        user=\"dataengineerteam\",\n",
    "        password=\"your_email_password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(open('fetch_data.sql', 'r').read())\n",
    "    records = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    df = pd.DataFrame(records, columns=columns)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def calculate_kpis(df):\n",
    "    # Calculate KPIs: Order Volume, Average Order Value, Average Basket Size\n",
    "    order_volume = len(df)\n",
    "    average_order_value = df['TotalAmount'].mean()\n",
    "    average_basket_size = df.groupby('OrderID')['ProductId'].count().mean()\n",
    "    # Generate the KPI report\n",
    "    report = f\"Weekly KPI Report:\\nOrder Volume: {order_volume}\\nAverage Order Value: {average_order_value}\\nBasket Size: {average_basket_size}\"\n",
    "    print(report)\n",
    "    return order_volume, average_order_value, average_basket_size\n",
    "\n",
    "    \n",
    "# Task to extract data from source systems\n",
    "fetch_data_task = PythonOperator(\n",
    "        task_id='fetch_data',\n",
    "        python_callable=fetch_data,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "calculate_kpis_task = PythonOperator(\n",
    "        task_id='calculate_kpis',\n",
    "        python_callable=calculate_kpis,\n",
    "        op_args=[fetch_data_task.output],\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "# Define task dependencies\n",
    "fetch_data_task >> calculate_kpis_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You create a DAG named **weekly_kpi_report** and define two tasks in this DAG: fetch_data_task >> calculate_kpis_task. The DAG is configured to run every Sunday at 23:59PM. [Astronomer - DAG scheduling and timetables in Airflow](https://docs.astronomer.io/learn/scheduling-in-airflow)\n",
    "\n",
    "The first task, **fetch_data_task**, aims to fetch data from the database. Here we join Order table and Order_Detail table and fetch all order data within the last 7 days.\n",
    "\n",
    "The second task, **calculate_kpis_task**, calculates the three KPIs that the marketing department is currently most concerned about.\n",
    "- Order Volume: This KPI quantifies the total number of orders made through the platform.\n",
    "- Average Order Value: The average amount of money spent by customers in a single order. \n",
    "- Basket Size: The average number of items purchased per order.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
