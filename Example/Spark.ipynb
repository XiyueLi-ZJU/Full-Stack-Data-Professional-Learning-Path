{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Chief Data Scientist of an e-commerce company, your main responsibility is to harness the power of data to improve customer experiences, drive business growth, and enhance operational efficiency. \n",
    "\n",
    "Recognizing the volume and complexity of data generated by e-commerce platform, you realize that traditional data processing tools are insufficient for your needs. Your need a robust solution that can process large datasets quickly, handle real-time data processing, and scale with the growing business.\n",
    "\n",
    "Therefore, you decide to use [ApacheSpark](https://spark.apache.org/), an open-source tool for big data processing and analytics. Below is an example of using ApacheSpark to analyze user activity logs stored in <span style=\"color:blue\">AzureBlobStorage</span> and user data stored in <span style=\"color:blue\">Azure SQL Database</span>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are interested in two metrics: <span style=\"color:orange\">total number of website visitors in the last 7 days </span> and <span style=\"color:orange\">how many of registered users visited the website in the last 7 days</span>. To get these two metrics, you perfom the following steps:\n",
    "\n",
    "- Read the website activity logs from Azure Blob Storage.\n",
    "- Extract information from user activity logs of the last 7 days to calculate the total number of website visitors, whether they are registered users or not.\n",
    "- Identify registered users from website visitors of the last 7 days, these users are recognized as 'active users'. \n",
    "- Read the 'User' table from AzureSQL to obtain the total number of registered users.\n",
    "- Calculate the percentage of active users (num_active_users/num_total_users)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:grey\">\n",
    "\n",
    "- The logs are organized and saved in AzureBlobStorage with the file structure: Year/Month/Day/Hour\n",
    "\n",
    "- Website Visitor -> Registered User -> Active User\n",
    "    - **Website Visitor**\n",
    "        - Any individual who visited the website, regardless of whether they have registered an account. \n",
    "        - Identified by unique IP address. \n",
    "    - **Registered User**\n",
    "        - An individual who completed a registration process and created a profile. \n",
    "        - Each registered user has a unique user_id. \n",
    "    - **Active User**\n",
    "        -  A registered user that has activities such as logging in, browsing content, and making orders within last 7 days. \n",
    "\n",
    "</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UserActivityAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Calculate the start and end dates\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=7)\n",
    "# List all dates within the last 7 days\n",
    "date_range = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Azure Blob Storage\n",
    "container_name = \"<container-name>\"\n",
    "path_to_logs = \"<path-to-logs>\"\n",
    "# Paths for all logs within the last 7 days\n",
    "file_paths = []\n",
    "for date in date_range:\n",
    "    year = date.strftime(\"%Y\")\n",
    "    month = date.strftime(\"%m\")\n",
    "    day = date.strftime(\"%d\")\n",
    "    for hour in range(24):\n",
    "        file_path = f\"wasbs://{container_name}/{path_to_logs}/{year}/{month}/{day}/{hour:02}/\"\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "# Read all logs from the last 7 days\n",
    "website_activity_logs_last_7_days_df = spark.read.csv(file_paths, header=True, inferSchema=True)\n",
    "# Calculate total number of visitors (based on unique IP addresses)\n",
    "total_visitors = website_activity_logs_last_7_days_df.select(countDistinct(\"ip_address\").alias(\"total_visitors\")).first()[0]\n",
    "print(\"Number of visitors in the last 7 days:\", total_visitors)\n",
    "\n",
    "# Calculate total number of active registered users (based on user_id) from the logs\n",
    "num_active_users = website_activity_logs_last_7_days_df.select(countDistinct(\"user_id\").alias(\"num_active_users\")).first()[0]\n",
    "print(\"Number of active registered users in the last 7 days:\", num_active_users)\n",
    "\n",
    "# Azure SQL connection\n",
    "sql_server_name = \"<sql-server-name>\"\n",
    "database_name = \"<database-name>\"\n",
    "table_name = \"User\"\n",
    "jdbc_url = f\"jdbc:sqlserver://{sql_server_name}.database.windows.net:1433;database={database_name};user=<username>;password=<password>\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"<username>\",\n",
    "    \"password\": \"<password>\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# Total number of registered users from the \"User\" table\n",
    "total_users_df = spark.read.jdbc(url=jdbc_url, table=table_name, properties=jdbc_properties)\n",
    "# Count total number of registered users\n",
    "num_total_users = total_users_df.count()\n",
    "print(\"Total number of registered users:\", num_total_users)\n",
    "\n",
    "pct_active_users  = num_active_users/num_total_users\n",
    "print(pct_active_users,\" '%' of registered users with activities in the last 7 days\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
